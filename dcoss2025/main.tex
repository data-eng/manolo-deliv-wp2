\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote
%Template version as of 6/27/2024

% \usepackage{cite}
\usepackage[noadjust]{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}

\usepackage{booktabs} % for professional tables
\usepackage{colortbl}
\usepackage{subcaption}
\usepackage{multirow}

\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[colorlinks=true, linkcolor=black, urlcolor=blue, citecolor=black]{hyperref}
\usepackage{array}

\newcommand{\tbfs}[3]{\textbf{#3\%}(#1\%,#2\%)}
\newcommand{\tbms}[3]{\hskip -0.2cm \textbf{#3\%}(#1\%,#2\%)}
\newcommand{\tbmv}[3]{\hskip -0.5cm \textbf{#3\%}(#1\%,#2\%)}
\newcommand{\tbmw}[3]{\hskip -0.6cm \textbf{#3\%}(#1\%,#2\%)}
\newcommand{\tbmm}[3]{\hskip -0.9cm \textbf{#3\%}(#1\%,#2\%)}
\newcommand{\tbq}{0.3cm}

\DeclareUnicodeCharacter{2212}{-}


% \def\anon{1}
\def\anon{0}


\begin{document}

\title{Investigation of Attention as a predictor \\
 for stream-data anomalies\thanks{Funding Acknowledgment in final version.}
}

\ifnum\anon=0

\author{\IEEEauthorblockN{Natalia Koliou}
\IEEEauthorblockA{\textit{Institute of Informatics and} \\
\textit{Telecomm., NCSR Demokritos}\\
Ag. Paraskevi, Greece \\
0009-0004-3920-9992}
\and
\IEEEauthorblockN{Georgios Dimitriou}
\IEEEauthorblockA{\textit{R\&D Department} \\
\textit{Four Dot Infinity}\\
Chalandri, Greece \\
0009-0006-7227-9612}
\and
\IEEEauthorblockN{Maria Sierra}
\IEEEauthorblockA{\textit{Data Science Department} \\
\textit{BitBrain}\\
Zaragoza, Spain \\
maria.sierra@bitbrain.com}
\and
\IEEEauthorblockN{Christoforos Romesis}
\IEEEauthorblockA{\textit{Institute of Informatics and} \\
\textit{Telecomm., NCSR Demokritos}\\
Ag. Paraskevi, Greece \\
0009-0001-6485-5548}
\and
\IEEEauthorblockN{\hskip 5em Stasinos Konstantopoulos}
\IEEEauthorblockA{\textit{\hskip 5em Institute of Informatics and} \\
\textit{\hskip 5em Telecomm., NCSR Demokritos}\\
\hskip 5em Ag. Paraskevi, Greece \\
\hskip 5em 0000-0002-2586-1726}
\and
\IEEEauthorblockN{Panagiotis Trakadas}
\IEEEauthorblockA{\textit{R\&D Department} \\
\textit{Four Dot Infinity}\\
Chalandri, Greece \\
0000-0002-5146-5954}
\and
\IEEEauthorblockN{Luis Montesano}\hfill
\IEEEauthorblockA{\textit{Chief Scientific Officer} \\
\textit{BitBrain}\\
Zaragoza, Spain \\
luis.montesano@bitbrain.com}\hfill}

\else

\author{\IEEEauthorblockN{Authors}
\IEEEauthorblockA{\textit{Affiliations}}}

\fi

\maketitle

\begin{abstract}
This paper presents a novel approach that employs attention mechanisms as a key indicator for detecting anomalies within time-series data. Machine learning models such as Autoencoders and Transformers are utilized for the tasks of signal reconstruction and sequence prediction, respectively. Autoencoders are designed to reconstruct input data, identifying noise through reconstruction errors; larger errors signify a higher likelihood of noise presence in the data segment. Conversely, Transformers are utilized to predict subsequent data points in a sequence, with noise identified through prediction errors. Building on these techniques, the proposed approach uses attention layers within machine learning models to estimate noise by assuming that lower attention values indicate noisy or, more generally, inconsistent data. The proposed method was evaluated for its effectiveness in detecting anomalies in electroencephalogram (EEG) signals acquired from medical-grade wearable devices. In this study, EEG signals are utilized to identify the sleep stages of subjects while they are sleeping. Each sleep stage is associated with distinct brain activity patterns characterized by specific waveforms. However, EEG signals collected from wearable devices during sleep are susceptible to noise, which complicates the accurate identification of contaminated data segments. The performance of the proposed approach was assessed against the established ground truth method used by the wearable manufacturer and other state-of-the-art baseline anomaly detection methods. The results indicate that the proposed method serves as a promising task-agnostic tool for anomaly detection in streaming data, particularly when compared to conventional baseline techniques.
\end{abstract}

\begin{IEEEkeywords}
AI, Machine learning, Transformers, Robustness, Time-Series, anomaly detection, noise estimation, outlier detection.
\end{IEEEkeywords}


\section{Introduction}

The term \emph{anomaly} is used in time series processing to indicate
a wide range of deviations and encompasses not only unforeseen events
in the observed system but also transient problems in the observation
mechanism. Indicatively, across various domains, an anomaly in the
observation data can be attributed to a cyberattack, a disease, a
faulty subsystem or, on the other hand, to a sensor momentarily
loosing contact or being heavily affected by noise in the environment
\cite{laptev_generic_2015,geiger_tadgan:_2020,ji_novel_2021,zhou_anomaly_2021}.

This vague definition of what constitutes an anomaly brings with it
the range of technical challenges that distinctively characterize the
field: the long and complex temporal dependencies that need to be
considered due to the priorly unknown duration of what constitutes an
event, non-stationarity when aiming at correctly separating anomalies
from data shifts due to long-term trends, high-dimensional data as
there is no clear prior knowledge of what variables are needed.
As conventional approaches often struggle to provide satisfactory
results, or are limited by the need to tune their parameters for each
specific application on a case-by-case basis, recent advancements in
\emph{deep learning} have gained significant attention in the research
community \cite{MEJRI2024124922}. And, given the vagueness of what
constitutes ground truth, the most successful approaches are
unsupervised or self-supervised: \emph{forecasting-based} approaches
train a neural network to predict the next datapoint in the sequence
and \emph{reconstruction-based} approaches train a neural network to
reconstruct the sequence from a learned, compressed representation.
In either case, the assumption is that a high error between the
predicted/reconstructed sequence and the actual data is indicative of
an abnormality.

However, as Mejri et al. \cite{MEJRI2024124922} note, there is no
general-purpose approach (or even paradigm) that works best across
domains and applications and performance depends on the use case and
the nature of the encountered anomalies; Deep learning methods appear
in general superior, but conventional approaches (mostly PCA) can also
in some cases perform. To address this, in this article we explore a
novel idea that aims to involve the use case into the training of the
anomaly detection model in a way that the system \emph{adapts itself}
to different use cases. In other words, instead of aiming at
general-purpose anomaly detector, we aim at a general-purpose way to
train a case-specific anomaly detector without direct supervision.

The core of the idea is that anomaly detection is a pre-processing
step for some sequence processing task. We operate under the
assumption that there is supervision for this downstream task,
although there is no supervision for what constitutes an anomaly.
We then make the following research hypothesis:
\emph{Anomalies are the parts of the sequence that have the property
that ignoring them gives superior performance despite the fact that
decisions are made from fewer datapoints.}

One can easily see how this maps directly to specific instances of
anomalies. For example, assuming a classification task on sensor data,
a burst of environment noise looks the same regardless of the correct
class during that period; a successful classifier would learn to
ignore such bursts as the same pattern maps to any class. As another
example, a successful model for predicting upcoming network traffic
would learn to ignore some kinds of bursts (although they might
indicate a cyberattack) and learn to emphasize `normal' bursts
(that indicate, for instance, the start of working hours).

Our contribution is the formulation of a methodology for leveraging
the outputs of intermediate layers of deep neural networks in order
to extract the level of significance the network places on the
different parts of the sequence being learnt. In the remainder of
this article, we first provide the necessary background
(Section~\ref{sec:bg}) and then proceed to describe our
methodology (Section~\ref{sec:method}), which we evaluate on
an EEG dataset where we have supervision for both a downstream task
(sleep stage prediction) \emph{and} carefully curated anomaly
annotations (Section~\ref{sec:exp}). We then present and discuss
the experimental results (Section~\ref{sec:results}) and conclude
(Section~\ref{sec:conc}).



%%%%%%%%%%%%
\section{Backrgound}
\label{sec:bg}
%%%%%%%%%%%%


One of the main frameworks in sequence processing are
\emph{recurrent neural networks} where the sequence is presented to
the network one token at a time and the network maintains a
\emph{hidden state} which distils the information needed from past
tokens to provide a context for the processing of the current token.
One of the most successful recurrent architectures is the
\emph{Long Short-Term Memory (LSTM)} where trainable \emph{gates}
control the flow of information to and from the hidden state
\cite{hochreiter-schmidhuber:1997}. This allows LSTM to capture long
temporal dependencies in a low-dimensional state representation
\cite{HOJJATI2024106106,10744017}.

LSTMs are often combined with other techniques, such as convolution
and encoder-decoder architectures. Encoder-decoder LSTMs, in
particular, learn a compressed representation of the data. When
training the decoder to reconstruct the original sequence back
(which is known as \emph{autoencoding}), the compressive encoding is
trained to drop information that is not detrimental for the loss
estimation. Anomalies (in the sense of patterns not encountered during
training) can then be identified by higher reconstruction error
\cite{SGUEGLIA2022170,aerospace6110117}.
Reconstruction error over autoencoding has been used extensively for
anomaly detection in various architecture besides LSTM
\cite{10.1145/3691338}, and its limitations are well-understood:
Autoencoders struggle with high-dimensional data, as it is up to the
system designer to find the layer widths (effectively, the level of
compression) that drop the correct amount of information.
Further, Autoencoders are limited with the respect to the kind of
information they drop: Since this decision is driven by a loss that
compares the reconstructed sequences against the input sequence, a
commonly occurring pattern will be retained even when it is an anomaly
in a given context.

Besides recurrency, the other major approach to sequence-processing is
the \emph{Transformer} architecture. Transformers are Autoencoders
based on the \emph{self-attention} mechanism \cite{vaswani-etal:2017}.
Unlike LSTMs and other recurrent architectures, Transformers receive
the complete sequence as input and model relationships across the
entire sequence. This allows gradients to flow directly across the
entire sequence, rather than being propagated step by step, making it
easier to discover long-distance dependencies.
%
At the core of the Transformer architecture lies the self-attention
mechanism, which enables the model to assign different levels of
importance to elements in the input sequence
based on the value of \emph{any other element in the sequence.}
Specifically, Transformers learn three sets of weights which are
applied to the input to get three vectors: the \emph{query (Q)}, the
\emph{key (K)}, and the \emph{Value (V)}.
The attention mechanism computes the \emph{similarity score} $QK^T$
which is a $n\times n$ matrix that determines the contribution of each
element in the final representation of each other element. The
similarity score is scaled and softmax'ed into a matrix of weights,
which are applied to the value vector. This yields the representation
%
$\mathrm{softmax}\left(QK^T / \mathrm{sqrt}(d_k)\right)\cdot V$
%
where each element contains information aggregated from the entire
sequence, improving the model's ability to detect long-range dependencies.



%%%%%%%%%%%%
\section{Research Methodology}
\label{sec:method}
%%%%%%%%%%%%

\subsection{Research Hypothesis}
\label{sec:method:hypothesis}

As discussed in the previous section, reconstruction and prediction
errors are widely used as key indicators for anomaly detection in
time-series data due to their intuitive appeal and straightforward
implementation. However, these approaches do not take into account
differences in the nature of what is considered an anomaly for each
use case.

As we framed our work in a context where there is no anomaly
supervision, it follows that it is also not possible to select
training data that is not contaminated with anomalies. This means that
the model may inadvertently learn to reconstruct anomalies.
Additionally, reconstruction-based methods often struggle to detect
contextual anomalies, where an observation may be anomalous only in
specific temporal or multivariate contexts. For example, a
high-temperature reading might be expected in the summer but anomalous
in the winter, and reconstruction models may overlook such contextual
nuances.

Similarly, prediction error, which measures deviations between
predicted and actual values, can be susceptible to noise and
non-stationarity in time-series data. In highly dynamic systems,
normal variations may result in significant prediction errors, leading
to false positives. Moreover, models relying on prediction error often
assume that future patterns can be reliably forecasted based on past
observations, an assumption that may not hold in volatile or chaotic
systems.

On the other hand, the attention mechanism offers an alternative,
currently unexplored, way to extract indications about what parts of
the sequence are anomalies. The hypothesis is that the part of the
sequence that receives the least attention while performing a task
relevant to the use case, then is this part is an anomaly. The
intuition is that neural networks will happily overfit the data
when they are given enough parameters to do so. Such a network might
not be good to actually perform the task, but is good at recognizing
two ways in which a sub-sequence is anomalous: (a) it does not follow
any pattern that was boosted (gradient-wise) by the training;
(b) it follows a pattern that is inconsistent, it is sometimes
associated with one class on the task and sometimes with an another,
so it alternates between being boosted and penalized by the loss
function, again resulting in low attention.

To investigate this hypothesis, we experimented with several methods
for anomaly and noise detection ranging from attention-based methods
to state-of-the-art machine learning approaches, as well as
conventional anomaly detection methods. These are listed in
Table~\ref{tab1} and described in more detail in the remainder of this
section.


\begin{table}[bt]
\centering
\caption{Methods under comparison.}
\label{tab1}
\begin{tabular}{lp{4cm}p{2cm}}
\toprule
\emph{Acronym}   & \emph{Architecture}& \emph{Detection}  \\
\midrule
\textit{LSTM}    & LSTM Autoencoder   & Reconstruction  \\
\textit{C-LSTM}  & Convolutional LSTM Autoencoder
                                      & error  \\
\textit{AE\_err} & Attention-based Autoencoder
                                      &   \\
\midrule
\textit{TP\_err} & Transformer Predictor
                                      & Prediction error  \\
\midrule
\textit{AE\_att} & Attention-based Autoencoder
                                      & Attention \\
\textit{TP\_att} & Transformer Predictor &  \\
\midrule
\textit{PCA}     & \multicolumn{2}{l}{Principle component analysis} \\
\textit{MNE}     & \multicolumn{2}{l}{IIR filter} \\
\bottomrule
\end{tabular} 
\end{table}


\subsection{Reconstruction and Prediction Error}

The \emph{LSTM Autoencoder (LSTM)} uses a sequence-to-sequence
architecture with LSTM layers for both encoding and decoding. The
encoder compresses the input into a fixed-size latent representation
by processing the input sequence and retaining the final hidden state
of the LSTM. This is achieved using an LSTM layer, followed by a
dropout layer for regularization, and a fully-connected layer for
dimensionality reduction. The decoder then processes this compressed
representation using the reverse architecture (FC, dropout, and LSTM)
to reconstruct the original data.

In this architecture, fully connected (FC) layers process the final
hidden state of the LSTM (the last timestep in the sequence) as a
single, comprehensive representation of the entire input
sequence. This output is then projected into a lower-dimensional
latent space through a linear transformation. While this approach is
computationally efficient, it assumes that the LSTM's final hidden
state sufficiently captures all relevant temporal dependencies. As a
result, it can struggle to retain fine-grained temporal details,
especially for data like EEG signals, where localized patterns are
crucial.

The \emph{Convolutional LSTM Autoencoder (C-LSTM)} enhances feature
extraction by combining LSTM layers with convolutional layers. The
key difference between the LSTM and C-LSTM architectures lies in how
dimensionality reduction is achieved in the encoder and decoder: the
first uses fully connected (FC) layers, while the latter uses
Conv1D layers. These operate directly on the sequence of hidden states
produced by the LSTM. By applying a kernel across the temporal
dimension, they extract localized patterns and dependencies within the
sequence. This convolutional operation integrates information from
multiple timesteps, creating a more nuanced and structured
representation. After convolution, the output is reduced to a
lower-dimensional latent space, where temporal features are preserved
and compactly encoded. This method emphasizes localized temporal
dynamics while reducing dimensionality.

The \emph{Attention-based Autoencoder (AE\_err)}
combines convolutional layers with an attention mechanism to
reconstruct the input data, again using the convolutional layers to
capture local features while replacing LSTM with attention to capture
long-term patterns.

Fig.~\ref{fig:Fig2} illustrates this architecture. The input to the
encoder consists of a sequence of 240 measurements from two
simultaneous channels, along with a same-size sequence of time
representation. The input data passes through the encoder and is
compressed into a latent representation of size \( 1 \times 8 \),
where the first dimension represents a single compressed time step,
and the second dimension corresponds to eight learned features. This
is achieved by applying multi-head attention to the input data,
followed by a dropout layer for regularization, and a convolutional
layer for dimensionality reduction. The decoder then processes this
compressed representation using the reverse architecture (transposed
convolution, dropout, and attention) to reconstruct the original data,
capturing both trends and amplitudes.

\begin{figure}[tb]
    % \vskip -0.2in 
    \centering
    \includegraphics[width=1\columnwidth]{images/Fig2.png}  
    \caption{\label{fig:Fig2} AE\_err/AE\_att architecture.}
    % \vskip -0.0in 
\end{figure}

In all three autoencoding systems, anomaly detection is based on the
assumption that the compressed latent representation preserves only
recurring, periodic fluctuations and trends. Atypical spikes, often
caused by noise, do not cause enough loss to be worth the space to
represent them (in terms of nodes in the latent representation).
Therefore, the level of anomaly is estimated as the reconstruction
error, the difference between the original input sequence and the
sequence decoded from the latent representation.

The \emph{Transformer Predictor (TP\_err)} method utilizes a
Transformer that uses multi-head attention for time-series
forecasting. It consists of a sequence-to-sequence architecture, with
multi-head attention layers in both the encoder and decoder
components. The encoder captures temporal dependencies in the input
sequence, while the decoder predicts the next sequence based on these
encoded features.

Fig.~\ref{fig:Fig3} illustrates this architecture. The input consists
of a sequence of 240 measurements from two simultaneous channels,
along with a same-size sequence of time representation. This data
passes through the embedding layer, which applies multi-head attention
to capture key temporal patterns. The output is then processed with
dropout regularization and passed through a LeakyReLU activation
function to introduce non-linearity.


\begin{figure}[tb]
    % \vskip -0.2in 
    \centering
    \includegraphics[width=0.65\columnwidth]{images/Fig3.png}
    \caption{\label{fig:Fig3} TP\_err/TP\_att architecture.}
    % \vskip -0.0in 
\end{figure}

The TP\_err method estimates noise through prediction error, i.e. the
difference between the model's predicted output and observed
values. When the model predicts the next time step in the sequence, a
significant difference between the predicted and actual values
suggests that the input data may be noisy.



\subsection{Attention-Based Detection}

The exact same architectures as in AE\_err and TP\_err above are also used
for the respective attention-based detection methods
\emph{Attention-based Autoencoder (AbAE\_att)} and \emph{Transformer
Predictor (TP\_att)}, except that now anomaly is estimated by the
attention weights.

The key idea is that when a part of the sequence receives a low
attention weight, it suggests that the information at that moment is
likely noisy and, therefore, unimportant for the task.


\subsection{Conventional Approaches}

Alongside machine learning methods, conventional techniques provide a
reliable alternative for detecting noise in time-series data and are
commonly utilized. Among the various conventional methods proposed by
many researchers over the years, a statistical method and a
signal-processing technique have been considered for this work.

\emph{Principal Component Analysis (PCA)} is a linear dimensionality
reduction technique. It analyzes a data table where observations are
described by quantitative dependent inter-correlated variables. With
PCA, the important information is extracted from the table and
represented in a new set of orthogonal variables, called principal
components \cite{bro2014principal}. The similarity patterns of the
observations and the variables can then be depicted as points on maps
\cite{abdi2010principal}.

\emph{Multinomial Noise Exponential filtering (MNE)} is a method used
to remove unwanted frequencies from time-series data, typically EEG
signals. It applies a bandpass filter to the data, allowing signals
within a specific frequency range to pass through while reducing
frequencies outside this range. MNE Filtering is implemented using the
MNE python library, which provides tools for filtering and analysing
neurophysiological data.




%%%%%%%%%%%%
\section{EXPERIMENT SETUP}
\label{sec:exp}
%%%%%%%%%%%%



This study employs a case analysis to validate the efficacy of the proposed noise estimation methods. The focus is detecting noise within electroencephalographic (EEG) signals, recorded via headbands utilized during slumber to monitor various stages of the user's sleep cycle.

\subsection{Test case description}

One of the main concerns when dealing with electroencephalographic signals (EEG) is assuring that clean data with a high signal-to-noise ratio is recorded. The EEG signal amplitude is in the microvolts range, and it is easily contaminated with noise, known as artifacts, which need to be filtered from the neural processes to keep the valuable information needed for different applications.

In this domain, an artifact is denoted as any component of the EEG signal not directly produced by human brain activity, making the system register noise that contaminates the neural EEG data. The ability to recognize these artifacts is the first step in removing them. EEG artifacts can be classified depending on their origin, which can be physiological or external to the human body (technical/non-physiological). Fig.~\ref{fig:Fig1} shows some examples of EEG signals contaminated with noise.

% \begin{figure}
%     % \vskip -0.2in 
%     \centering
%     \includegraphics[width=0.90\columnwidth]{images/Fig1n.png}     
%     \vspace{0.15em}
%     \caption{\label{fig:Fig1} Examples of the temporal visualization of EEG signals and coloring of noisy segments.}
%     % \vskip -0.0in 
% \end{figure}

\begin{figure}[tb]
    \centering
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/bb1.png}     
    \end{minipage}
    \vspace{0.05cm}
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/bb2.png}     
    \end{minipage}
    \vspace{0.05cm}
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/bb3.png} 
    \end{minipage}
    \vspace{0.05cm}
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/bb4.png}
    \end{minipage}
    \caption{\label{fig:Fig1} Examples of the temporal visualization of EEG signals and coloring of noisy segments.}
\end{figure}


In this figure, pink-colored areas are typical of low-frequency noise (0.2-4Hz), which is mainly due to perspiration originating from small drops of sweat produced by the skin glands, which cause changes in the electrical baseline of the electrodes. Brown-colored and green-colored areas are typical of high-frequency noise (30-45Hz) that may originate from electrical activity produced by the muscles when they are contracted, like, for example, muscle tension in the jaw or forehead that can take place when clenching or frowning, respectively. Orange-colored areas are typical of high-amplitude noise that may be due to temporary failures in contact between the EEG sensor and the scalp produced by touching the sensor or by spontaneous changes in electrode-skin contact.

In this analysis, EEG signals collected from a headband with two EEG channels synchronized with medical-grade EEG devices are considered. The recorded signal frequency for each channel of the headband is 128Hz. These signals are grouped into consecutive 30-second segments, and each segment is further annotated by three experts, into one of five sleep stages: Wake, N1, N2, N3, and REM. These stages correspond to specific brain activity patterns, such as slow eye movements, sleep spindles, and other characteristic waveforms. The goal of the current analysis is to detect the presence of noise, if any, at any of these segments. In total, 56 recordings were examined. Each recording refers to the EEG signals acquired by the headband of a user during a night-long sleep. These signals are grouped into 30-second consecutive segments.

As a ground-truth method to evaluate the results of the proposed noise estimation methods, the original estimation method used by the headband manufacturer is considered. This method consists of task-specific algorithms to automatically estimate noise and evaluate the overall quality of EEG signals, identifying the artifacts in recordings made using the wearable textile headband.


\subsection{Data Pre-preocessing}

Data normalization is required for the machine learning methods to
ensure robust model training and reliable outcomes. It is performed
using statistics derived from the entire training dataset instead of
relying on per-batch calculations. The median and
\emph{interquartile range (IQR)} are used instead of the mean and
standard deviation, respectively, to improve robustness against
outliers. The median measures central tendency and is resistant to
extreme values, and IQR is a measure of statistical dispersion that
represents the spread of the middle 50\% of a dataset and reduces the
influence of outliers by focusing on the range within which the
central portion of the data lies.

% For a particular feature of a time-series $x$, its normalized value $x_{\text{norm}}$ is given:

% \begin{equation}
%     x_{\text{norm}} = \frac{x - \mathrm{median}(x)}{\mathrm{IQR}(x)} \label{eq:robust_norm}
% \end{equation}

% where $\mathrm{median}(x)$ and $\mathrm{IQR}(x)$ are the feature's median value and IQR respectively.

PCA and MNE require raw data that preserves the characteristics of the
original signal, so no normalization is applied for these methods.

To train the machine learning models, the available recordings were
randomly split into training (43 recordings), validation (3
recordings), and testing subsets (10 recordings). Among the testing
recordings, six had zero or one noisy segments are not reported here
as it makes little sense to compare methods on having identified a
single datapoint. For the record, only PCA identified the noisy
segment in only one of the segments.

Table~\ref{tab2} gives the absolute and relative noise density for the
remaining four recordings, arranged in descending order.
Specifically, the table gives the count of 30-second segments within
which at least one artifact is annotated as noise in the ground-truth
labelling. Note that recordings are \emph{not} of equal length.

What is noteworthy is that Recording~A has considerably different
noise rates between the two channels. Since the signals from the
two channels are heavily correlated, this presents an opportunity
for the machine learning methods to demonstrate learning a
comparative model that exploits the fact that the noisy parts of
HB2 are not correlated to their corresponding parts in HB1. However
this is a difficult theory to construct, since it requires
`discovering' correlation first.


\begin{table}[bt]
\caption{Absolute number and percentage of segments with artifacts in
  each channel and recording session.}
\centering
\renewcommand{\arraystretch}{1.3} % Adjust row height
\begin{tabular}{lrrrr}
\toprule
RecID &  A         &  B       &  C & D \\
\midrule
HB1   &   0        & 57 (5\%) & 27 (3\%) & 9 (1\%) \\

HB2   & 151 (14\%) & 56 (5\%) & 26 (3\%) & 9 (1\%) \\
\bottomrule
\end{tabular}
\label{tab2}
\end{table}



\subsection{Training Process and Hyper-parameters}

The implementations of the methods in Table~\ref{tab1} that we used in
our experiments are publicly available. Our implementation of the
machine learning methods have been reposited in Zenodo.\footnote{To preserve
  anonymity the Zenodo record is not published but left as a draft;
  reviewers can access it at
  \url{https://zenodo.org/records/14842198?preview=1&token=eyJhbGciOiJIUzUxMiJ9.eyJpZCI6IjNjMWE3YTg3LTM4MzgtNGNlMC1hNDE4LTJjMWJlMjU5YjA3NyIsImRhdGEiOnt9LCJyYW5kb20iOiJiODVmNmVhMDE1NjczMThjNjI2MTI1ODQyZTExOWIxMiJ9.o4gCR2U_bkKruC97ZdexHkU7iVI2q28Cx_0tD8xkPjGyjoPdWNqsASLj62O0hhfdoFxliJFKKrQdrAWVoeLcXw}}
PCA is implemented using the
Frouros\footnote{Documentation and source code are available at
  \url{https://github.com/IFCA-Advanced-Computing/frouros}.
\ifnum\anon=0
  Access to the specific code designed and parametrized for this
  paper can be discussed with the authors from Four Dot Infinity.
\fi
}
open-source Python library for drift detection.
MNE is used as implemented and configured in the `MNE Tools' Python
package for exploring, visualizing, and analyzing human
neurophysiological data.\footnote{Available from \url{https://mne.tools} and Pypi.}
MNE is an IIR filter with pre-configured cut-offs specifically
targeting EEG data.

To process the data with the \emph{AE} and \emph{TP} methods, we split
each 30-second segment of EEG data (3840 samples per channel) into 16
smaller chunks of 240 samples each. This point is moot for \emph{LSTM},
\emph{C-LSTM}, \emph{PCA} and \emph{MNE}.

The Autoencoder methods are trained on sequence reconstruction. The
Predictor methods are trained on predicting sleep stage.
%
To balance the autoencoders' focus on both the amplitude and trends of the
time-series data, we define a custom loss function, called
\emph{BlendedLoss}. This function combines the median and mean of the
powered absolute differences between the predicted values ($\hat{x}$)
and the target values ($x$):
%
$$
\text{Loss} =
  (1 - b)\cdot\mathrm{median}(\lvert \hat{x} - x \rvert^p) +
  b\cdot\mathrm{mean}(\lvert \hat{x} - x \rvert^p)
$$
%
where $p$ is the power parameter that controls the sensitivity of the
loss to differences and $b$ the \emph{blend factor} that controls
the trade-off between learning the overall trend (median error) and
closely following local patterns (mean error).
% A systematic
% investigation of various blend values within the range [0.1, 0.8]
% reveals the impact on the model's performance in data reconstruction.

Revisiting our research hypothesis, we expect methods trained on
predicting sleep stage to outperform methods trained on autoencoding
since they have access to task-specifc labels. More generally our
methods are ordered as follows in terms of task-specific knowledge
they have access to:
%
\begin{enumerate}
\item \emph{MNE} is specifically, expertly designed to detect noise in
  EEG signals and has proven to be very effective on this task.
  \emph{PCA} is a general-purpose drift detection method, but for
  the purposes of this paper has been carefully calibrated on the
  training data to look for `drifts' that have the expected duration
  before returning to the previous data distribution.
\item \emph{AE\_att} and \emph{TP\_att} implement our hypothesis that
  the attention mechanism can exploit supervision unrelated to anomaly
  detection to automatically extract task-specific knowledge of
  anomalies.
\item \emph{LSTM}, \emph{C-LSTM}, \emph{AE\_err} and \emph{TP\_err}
  are general-purpose autoencoders with minimal access to task-specific
  knowledge in the form of a task-specific loss function.
\end{enumerate}
%
This ordering reflects our prior expectation regarding their relative
performance.

For the training configuration, we set the batch size to 512 and
trained the models for a maximum of 1000 epochs with patience of 30
epochs, meaning that if the validation loss does not improve for 30
consecutive epochs, training will stop. We set the learning rate to
1e-4 and use the Adam optimizer to adjust the model
weights. Additionally, we implement a ReduceLROnPlateau scheduler to
adjust the learning rate dynamically based on the validation loss. If
the validation loss plateaus, the scheduler reduces the learning rate
to push the model to fit finer patterns.

%Since dataset has low variability and extreme outliers, even the
%relatively small networks we used are able to overfit; Which we
%consider a positive quality, as argued in
%Section~\ref{sec:method:hypothesis}.


%%%%%%%%%%%%
\section{Results and Discussion}
\label{sec:results}
%%%%%%%%%%%%

We prepared three validation/testing setups. In the first setup
validation and testing scores are calculated on the original 30-sec
segments where each segments is annotated as `noise' if it includes at
least one sample marked as `noise' in the ground-truth annotation.
In the 5min and 10min-window setups segments evaluation was performed
on 5min and 10min windows. If a method reports noise on any part of
the window and the groud truth also annotates as noisy any part of the
window, the window counts as a true positive. Obviously, these are
easier tasks than the original 30-sec segmentation on two
grounds: (a) positives get less sparse so task becomes less of a
needle-in-a-haystack problem, and (b) learners have access to a longer
context for the same number of input token, which know to be an
important factor in sequence processing \cite{Lee_2021}.

\input{tab_results}

Table~\ref{tab:results} presents F-score, Precision, and Recall
metrics for the evaluated methods on all three evaluation setups.
%
Since all methods give a numerical estimation and not a binary
decision, a threshold was established. The threshold was calculated
on the training data as the number that makes 1\% of the data come out
as noise. This is the only piece of prior domain knowledge shared by
all learners.
%
F-score is calculated for $\beta=2$, in order
place more weight on recall than precision. This is due to fact that
the dataset is very unbalanced and noise instances are rare, even in
the 10min-window setup. F-score is adapted accordingly to reflect
that recall is harder to achieve than precision.

% NOTE: decided against it to not have the actual application
% influence the research result
%In this application, our primary objective is to identify as many
%segments as possible that contain artifacts while allowing for some
%tolerance regarding detecting noisy segments. The principal aim should
%be to reduce the number of instances requiring the application of
%reliable yet non-automated anomaly detection methods. Consequently,
%the key performance metric to prioritize is Recall. For this reason,
%the F2 score is considered, which is a weighted harmonic mean of
%precision and recall, and where recall is given more importance than
%precision.

The first observation is that by comparing the three sub-tables we can
immediatelly see that the three windows behave as expected, with
results improving with longer windows. By comparing horizontally from
right to left we also see that results improve as noise gets
denser.\footnote{Note that HB1-A is out-of-order in this respect, as
  it has no noise.}
We cannot speculate on whether the top-to-bottom improvement
is due to the longer context or due to denser positives. But either
way, we have clear indications about how task difficulty scales across
the table.

What is directly relevant for our hypothesis are the comparisons
between
(a) attention-based anomaly detection (AE\_att and TP\_att) against
the error-based anomaly detection from the same models (AE\_err and
TP\_err), and (b) models trained on the sleep stage task (TP) against
autoencoded models (AE).
TP\_att generally outperforms all four TP/AE\_err/att combinations,
although autoencoding proved better on HB1-C (primarily LSTM and
secondarily AE\_att) with the gap becoming more pronounced on the
denser setups. 
Although the conditions present in HB1-C are worth investigating,
the results show that the ideas presented here are validated and
promising.

What is also noteworthy is that TP\_att outperforms the
task-calibrated conventional methods on HB2-A and HB2-B.
Regarding HB2-A it is worth investigating whether the transformer has
`discovered' the lack of correlation between HB1-A and HB2-A on noisy
segments.
Regarding HB2-B, a possible explanation is that TP\_att is more robust
to noise density considerably above the hard-wired 1\%: it suffers
the unavoidable precision loss just as all methods, but it gets a
comparatively higher F-score through perfect recall.



\section{Conclusions and Future Work}
\label{sec:conc}

This paper investigates the innovative application of attention
mechanisms within machine learning models as pivotal indicators for
anomaly detection in time-series datasets. Two methodologies, namely
an Autoencoder and a Transformer, are examined, with their
performances benchmarked against conventional techniques and other
advanced machine-learning approaches. The efficacy of the proposed
methodology is assessed utilizing EEG signals sourced from wearable
sleep-monitoring devices measuring Precision and Recall against a
manufacturer's established ground truth methodology. The findings
indicate that attention-based approaches, particularly the Transformer
Predictor, exhibit promising capabilities in identifying anomalies,
particularly with extended time windows for analysis. The study
concludes that attention mechanisms significantly enhance anomaly
detection in streaming data environments.

The current study acts as a proof of concept, illustrating the
potential of attention mechanisms as key-indicators of anomalies in
time series data. Subsequent steps will entail exploring additional
architectures beyond the AbAE\_att and TP\_att methods analyzed
herein. Additionally, the investigation will focus on the performance
parameters of attention-based techniques, such as the choice of
time-window segments, to develop a task-agnostic approach for anomaly
detection.



\ifnum\anon=0

%%%%%%%%%%%%
\section*{Acknowledgment}
%%%%%%%%%%%%

This research was co-funded by the European Union under GA no. 101135782 (MANOLO project). Views and opinions expressed are however those of the authors only and do not necessarily reflect those of the European Union or CNECT. Neither the European Union nor CNECT can be held responsible for them. AWS resources were provided by the National Infrastructures for Research and Technology GRNET and funded by the EU Recovery and Resiliency Facility.

\fi

% \section*{References}

\bibliographystyle{IEEEtranDOI}
\bibliography{refs}

\end{document}


% LocalWords:  Autoencoders stationarity datapoint Mejri PCA LSTM IQR
% LocalWords:  Autoencoder dimensionality LeakyReLU BlendedLoss MNE
% LocalWords:  neurophysiological overfit Frouros MANOLO CNECT
