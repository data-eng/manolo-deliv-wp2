% 14 pages including references and appendices
% only one contact author, Springer License to Publish
% https://resource-cms.springernature.com/springer-cms/rest/v1/content/19790018/data/SNCS_ProceedingsPaper_LTP_ST_SN_Switzerland
% Submit a zip  containing:
% PDF; tex source files including figures and tables; supplementary materials; license

\documentclass[runningheads]{llncs}

\usepackage[T1]{fontenc}

\usepackage{rotating}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}

\usepackage{booktabs} % for professional tables
\usepackage{colortbl}
\usepackage{subcaption}
\usepackage{multirow}

\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[colorlinks=true, linkcolor=black, urlcolor=blue, citecolor=black]{hyperref}
\usepackage{array}

\newcommand{\tbfs}[3]{\textbf{#3\%}(#1\%,#2\%)}
\newcommand{\tbms}[3]{\hskip -0.2cm \textbf{#3\%}(#1\%,#2\%)}
\newcommand{\tbmv}[3]{\hskip -0.5cm \textbf{#3\%}(#1\%,#2\%)}
\newcommand{\tbmw}[3]{\hskip -0.6cm \textbf{#3\%}(#1\%,#2\%)}
\newcommand{\tbmm}[3]{\hskip -0.9cm \textbf{#3\%}(#1\%,#2\%)}
\newcommand{\tbq}{0.3cm}

\DeclareUnicodeCharacter{2212}{-}


\newcommand{\deleted}[1]{\textbf{DEL:} #1}
\renewcommand{\deleted}[1]{}

\begin{document}

\title{Self-Attention as a Predictor of EEG Anomalies}

\author{Natalia Koliou\inst{1}\orcidID{0009-0004-3920-9992} \and
Maria Sierra\inst{2} \and
Christoforos Romesis\inst{1}\orcidID{0009-0001-6485-5548} \and
Stasinos Konstantopoulos\inst{1}\orcidID{0000-0002-2586-1726} \and
Luis Montesano\inst{2}
}

\institute{Institute of Informatics and Telecommunications,
  NCSR Demokritos, Ag. Paraskevi, Greece
  \email{lncs@springer.com}
  \and BitBrain, Zaragoza, Spain
}
  
\authorrunning{N. Koliou et al.}


\maketitle

\begin{abstract}
% 150--250 words. Now 270.

One of the main concerns when dealing with electroencephalographic
signals (EEG) is assuring that clean data with a high signal-to-noise
ratio is recorded. The relevant denoising methods tend to have
a narrow scope of application as what is noise for one
application might be useful signal for some other application and
there no general-purpose approach (or even paradigm) that works best
across domains and applications.
%
Machine learning methods are often used for this task, by
training Autoencoders and Transformers on reconstruction and
prediction, and then assuming the reconstruction/prediction error as
an indication of anomalies. These approaches only take into account
the morphology of the stream, and are not aware of the different,
often highly contextualized, aspects of artifacts.

In this article we explore the novel idea that we can create
application-specific artifact detectors by training an
attention-based deep neural network and then extracting from the
attention layer information about what is ignored.
This removes the most pressing challenge of artifact detection, namely
that artifacts are vaguely defined and thus difficult to directly
supervise, and allows application-specific artifact patterns to be
extracted from non artifact-related supervision.
%
We evaluated our method using electroencephalogram (EEG) signals on a
sleep-stage labeling task. The performance of the proposed approach
was compared against reconstruction/prediction error and against
EEG-specific noise detection methods. The results indicate that the
proposed method is a promising task-agnostic tool for anomaly
detection in streaming data.

\keywords{Machine learning \and Biomedical data \and EEG \and denoising}
\end{abstract}



\section{Introduction}

One of the main concerns when dealing with electroencephalographic
signals (EEG) is assuring that clean data with a high signal-to-noise
ratio is recorded. The EEG signal amplitude is in the microvolts
range, and it is easily contaminated with noise, known as artifacts,
which need to be filtered from the neural processes to keep the
valuable information needed for different applications.

In this domain, an artifact is denoted as any component of the EEG
signal not directly produced by human brain activity, making the
system register noise that contaminates the neural EEG data. The
ability to recognize these artifacts is the first step in removing
them. EEG artifacts can be classified depending on their origin, which
can be physiological or external to the human body
(technical/non-physiological).


\begin{figure}[tb]
    \centering
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/bb1.png}     
    \end{minipage}
    \vspace{0.05cm}
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/bb2.png}     
    \end{minipage}
    \vspace{0.05cm}
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/bb3.png} 
    \end{minipage}
    \vspace{0.05cm}
    \begin{minipage}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/bb4.png}
    \end{minipage}
    \caption{\label{fig:Fig1} Examples of the temporal visualization of EEG signals and coloring of noisy segments.}
\end{figure}

Fig.~\ref{fig:Fig1} shows some examples of EEG signals contaminated
with noise. In this figure, pink-colored areas are typical of
low-frequency noise (0.2-4Hz), which is mainly due to perspiration
originating from small drops of sweat produced by the skin glands,
which cause changes in the electrical baseline of the
electrodes. Brown-colored and green-colored areas are typical of
high-frequency noise (30-45Hz) that may originate from electrical
activity produced by the muscles when they are contracted, like, for
example, muscle tension in the jaw or forehead that can take place
when clenching or frowning, respectively. Orange-colored areas are
typical of high-amplitude noise that may be due to temporary failures
in contact between the EEG sensor and the scalp produced by touching
the sensor or by spontaneous changes in electrode-skin contact.

As understood from the above, there is a variety of artifacts, both
technical and physiological, each with different characteristics.
Furthermore, and in particular regarding the physiological artifacts,
what is noise for one application might be useful signal for some
other application. It is well-known that there is no general-purpose
approach (or even paradigm) that works best across domains and
applications and performance depends on the use case and the nature of
the encountered anomalies \cite{MEJRI2024124922}.

\deleted{As conventional approaches often struggle to provide satisfactory
results, or are limited by the need to tune their parameters for each
specific application on a case-by-case basis, recent advancements in
\emph{deep learning} have gained significant attention in the research
community \cite{MEJRI2024124922}. And, given the vagueness of what
constitutes ground truth, the most successful approaches are
unsupervised or self-supervised: \emph{forecasting-based} approaches
train a neural network to predict the next datapoint in the sequence
and \emph{reconstruction-based} approaches train a neural network to
reconstruct the sequence from a learned, compressed representation.
In either case, the assumption is that a high error between the
predicted/reconstructed sequence and the actual data is indicative of
an abnormality.}

In the work described here, we present a method for automatically
adapting a deep-learned anomaly detector to different domains. In
other words, instead of aiming at a general-purpose anomaly detector
(which is unatainable for the reasons explained above), we aim at a
general-purpose way to train a case-specific anomaly detector without
direct supervision.
The core of the idea is that anomaly detection is a pre-processing
step for some sequence processing task. We operate under the
assumption that there is supervision for this downstream task,
although there is no supervision for what constitutes an anomaly.
We then make the following research hypothesis:
\emph{Anomalies are the parts of the sequence that have the property
that ignoring them gives superior performance despite the fact that
decisions are made from fewer datapoints.}

One can easily see how this maps directly to specific instances of
anomalies. For example, assuming a sleep-stage classification task on
EEG data, electrical activity produced muscle contraction will
have the same morphology regardless of the sleep stage and a
successful classifier will learn to ignore it; But the same patterns
might be considered useful signal for a different application of EEG
data.

Our contribution is the formulation of a methodology for leveraging
the outputs of intermediate layers of deep neural networks in order
to extract the level of significance the network places on the
different parts of the sequence being learned. In the remainder of
this article, we first provide the necessary background
(Section~\ref{sec:bg}) and then proceed to describe our
methodology (Section~\ref{sec:method}), which we evaluate on
an EEG dataset where we have supervision for both a downstream task
(sleep stage prediction) \emph{and} carefully curated anomaly
annotations (Section~\ref{sec:exp}). We then present and discuss
the experimental results (Section~\ref{sec:results}) and conclude
(Section~\ref{sec:conc}).



%%%%%%%%%%%%
\section{Background}
\label{sec:bg}
%%%%%%%%%%%%


One of the main frameworks in sequence processing are
\emph{recurrent neural networks} where the sequence is presented to
the network one token at a time and the network maintains a
\emph{hidden state} which distills the information needed from past
tokens to provide a context for the processing of the current token.
One of the most successful recurrent architectures is the
\emph{Long Short-Term Memory (LSTM)} where trainable \emph{gates}
control the flow of information to and from the hidden state
\cite{hochreiter-schmidhuber:1997}. This allows LSTM to capture long
temporal dependencies in a low-dimensional state representation
\cite{HOJJATI2024106106,10744017}.

LSTMs are often combined with other techniques, such as convolution
and encoder-decoder architectures. Encoder-decoder LSTMs, in
particular, learn a compressed representation of the data. When
training the decoder to reconstruct the original sequence back
(which is known as \emph{autoencoding}), the compressive encoding is
trained to drop information that is not detrimental for the loss
estimation. Anomalies (in the sense of patterns not encountered during
training) can then be identified by higher reconstruction error
\cite{SGUEGLIA2022170,aerospace6110117}.
Reconstruction error over autoencoding has been used extensively for
anomaly detection in various architecture besides LSTM
\cite{10.1145/3691338}, and its limitations are well-understood:
Autoencoders struggle with high-dimensional data, as it is up to the
system designer to find the layer widths (effectively, the level of
compression) that drop the correct amount of information.
Further, Autoencoders are limited with the respect to the kind of
information they drop: Since this decision is driven by a loss that
compares the reconstructed sequences against the input sequence, a
commonly occurring pattern will be retained even when it is an anomaly
in a given context.

Besides recurrency, the other major approach to sequence-processing is
the \emph{Transformer} architecture. Transformers are Autoencoders
based on the \emph{self-attention} mechanism \cite{vaswani-etal:2017}.
Unlike LSTMs and other recurrent architectures, Transformers receive
the complete sequence as input and model relationships across the
entire sequence. This allows gradients to flow directly across the
entire sequence, rather than being propagated step by step, making it
easier to discover long-distance dependencies.
%
At the core of the Transformer architecture lies the self-attention
mechanism, which enables the model to assign different levels of
importance to elements in the input sequence
based on the value of \emph{any other element in the sequence.}
Specifically, Transformers learn three sets of weights which are
applied to input of dimensionality $d$ to get the
\emph{query (Q)} vector, the \emph{key (K)} vector,
and the \emph{Value (V)} vector.
The attention mechanism computes the \emph{similarity score} $QK^T$
which is a $d \times d$ matrix that determines the contribution of each
element in the final representation of each other element. The
similarity score is scaled and softmax'ed into a matrix of weights,
which are applied to the value vector. This yields the representation
%
$\mathrm{softmax}\left(QK^T / \mathrm{sqrt}(d)\right)\cdot V$
%
where each element contains information aggregated from the entire
sequence, improving the model's ability to detect long-range dependencies.



%%%%%%%%%%%%
\section{Research Methodology}
\label{sec:method}
%%%%%%%%%%%%

\subsection{Research Hypothesis}
\label{sec:method:hypothesis}

As discussed in the previous section, reconstruction and prediction
errors are widely used as key indicators for anomaly detection in
time-series data due to their intuitive appeal and straightforward
implementation. However, these approaches do not take into account
differences in the nature of what is considered an anomaly for each
use case.

As we framed our work in a context where there is no anomaly
supervision, it follows that it is also not possible to select
training data that is not contaminated with anomalies. This means that
the model may inadvertently learn to reconstruct anomalies.
Additionally, reconstruction-based methods often struggle to detect
contextual anomalies, where an observation may be anomalous only in
specific temporal or multivariate contexts. For example, a
high-temperature reading might be expected in the summer but anomalous
in the winter, and reconstruction models may overlook such contextual
nuances.

Similarly, prediction error, which measures deviations between
predicted and actual values, can be susceptible to noise and
non-stationarity in time-series data. In highly dynamic systems,
normal variations may result in significant prediction errors, leading
to false positives. Moreover, models relying on prediction error often
assume that future patterns can be reliably forecasted based on past
observations, an assumption that may not hold in volatile or chaotic
systems.

On the other hand, the attention mechanism offers an alternative,
currently unexplored, way to extract indications about what parts of
the sequence are anomalies. The hypothesis is that the part of the
sequence that receives the least attention while performing a task
relevant to the use case, then is this part is an anomaly. The
intuition is that neural networks will happily overfit the data
when they are given enough parameters to do so. Such a network might
not be good to actually perform the task, but is good at recognizing
two ways in which a sub-sequence is anomalous: (a) it does not follow
any pattern that was boosted (gradient-wise) by the training;
(b) it follows a pattern that is inconsistent, it is sometimes
associated with one class on the task and sometimes with an another,
so it alternates between being boosted and penalized by the loss
function, again resulting in low attention.

To investigate this hypothesis, we experimented with several methods
for anomaly and noise detection ranging from attention-based methods
to state-of-the-art machine learning approaches, as well as
conventional anomaly detection methods. These are listed in
Table~\ref{tab1} and described in more detail in the remainder of this
section.


\begin{table}[bt]
\centering
\caption{Methods under comparison.}
\label{tab1}
\begin{tabular}{lp{4cm}p{2cm}}
\toprule
\emph{Acronym}   & \emph{Architecture}& \emph{Detection}  \\
\midrule
\textit{LSTM}    & LSTM Autoencoder   & Reconstruction  \\
\textit{C-LSTM}  & Convolutional LSTM Autoencoder
                                      & error  \\
\textit{AE\_err} & Attention-based Autoencoder
                                      &   \\
\midrule
\textit{TP\_err} & Transformer Predictor
                                      & Prediction error  \\
\midrule
\textit{AE\_att} & Attention-based Autoencoder
                                      & Attention \\
\textit{TP\_att} & Transformer Predictor &  \\
\midrule
\textit{MNE}     & \multicolumn{2}{l}{IIR filter} \\
\bottomrule
\end{tabular} 
\end{table}


\subsection{Reconstruction and Prediction Error}

The \emph{LSTM Autoencoder (LSTM)} uses a sequence-to-sequence
architecture with LSTM layers for both encoding and decoding. The
encoder compresses the input into a fixed-size latent representation
by processing the input sequence and retaining the final hidden state
of the LSTM. This is achieved using an LSTM layer, followed by a
dropout layer for regularization, and a fully-connected layer for
dimensionality reduction. The decoder then processes this compressed
representation using the reverse architecture (FC, dropout, and LSTM)
to reconstruct the original data.

In this architecture, fully connected (FC) layers process the final
hidden state of the LSTM (the last timestep in the sequence) as a
single, comprehensive representation of the entire input
sequence. This output is then projected into a lower-dimensional
latent space through a linear transformation. While this approach is
computationally efficient, it assumes that the LSTM's final hidden
state sufficiently captures all relevant temporal dependencies. As a
result, it can struggle to retain fine-grained temporal details,
especially for data like EEG signals, where localized patterns are
crucial.

The \emph{Convolutional LSTM Autoencoder (C-LSTM)} enhances feature
extraction by combining LSTM layers with convolutional layers. The
key difference between the LSTM and C-LSTM architectures lies in how
dimensionality reduction is achieved in the encoder and decoder: the
first uses fully connected (FC) layers, while the latter uses
Conv1D layers. These operate directly on the sequence of hidden states
produced by the LSTM. By applying a kernel across the temporal
dimension, they extract localized patterns and dependencies within the
sequence. This convolutional operation integrates information from
multiple timesteps, creating a more nuanced and structured
representation. After convolution, the output is reduced to a
lower-dimensional latent space, where temporal features are preserved
and compactly encoded. This method emphasizes localized temporal
dynamics while reducing dimensionality.

The \emph{Attention-based Autoencoder (AE\_err)}
combines convolutional layers with an attention mechanism to
reconstruct the input data, again using the convolutional layers to
capture local features while replacing LSTM with attention to capture
long-term patterns.
%
Fig.~\ref{fig:Fig2} illustrates this architecture. The input to the
encoder consists of a sequence of 240 measurements from two
simultaneous channels, along with a same-size sequence of time
representation. The input data passes through the encoder and is
compressed into a latent representation of size \( 1 \times 8 \),
where the first dimension represents a single compressed time step,
and the second dimension corresponds to eight learned features. This
is achieved by applying multi-head attention to the input data,
followed by a dropout layer for regularization, and a convolutional
layer for dimensionality reduction. The decoder then processes this
compressed representation using the reverse architecture (transposed
convolution, dropout, and attention) to reconstruct the original data,
capturing both trends and amplitudes.

\begin{figure}[tb]
\centering
\includegraphics[width=0.9\columnwidth]{images/Fig2.png}  
\caption{\label{fig:Fig2} AE\_err/AE\_att architecture.}
\end{figure}

In all three autoencoding systems, anomaly detection is based on the
assumption that the compressed latent representation preserves only
recurring, periodic fluctuations and trends. Atypical spikes, often
caused by noise, do not cause enough loss to be worth the space to
represent them (in terms of nodes in the latent representation).
Therefore, the level of anomaly is estimated as the reconstruction
error, the difference between the original input sequence and the
sequence decoded from the latent representation.

The \emph{Transformer Predictor (TP\_err)} method utilizes a
Transformer that uses multi-head attention for time-series
forecasting. It consists of a sequence-to-sequence architecture, with
multi-head attention layers in both the encoder and decoder
components. The encoder captures temporal dependencies in the input
sequence, while the decoder predicts the next sequence based on these
encoded features.
%
Fig.~\ref{fig:Fig3} illustrates this architecture. The input consists
of a sequence of 240 measurements from two simultaneous channels,
along with a same-size sequence of time representation. This data
passes through the embedding layer, which applies multi-head attention
to capture key temporal patterns. The output is then processed with
dropout regularization and passed through a LeakyReLU activation
function to introduce non-linearity.


\begin{figure}[tb]
\centering
\includegraphics[width=0.55\columnwidth]{images/Fig3.png}
\caption{\label{fig:Fig3} TP\_err/TP\_att architecture.}
\end{figure}

The TP\_err method estimates noise through prediction error, i.e. the
difference between the model's predicted output and observed
values. When the model predicts the next time step in the sequence, a
significant difference between the predicted and actual values
suggests that the input data may be noisy.



\subsection{Attention-Based Detection}

The exact same architectures as in AE\_err and TP\_err above are also used
for the respective attention-based detection methods
\emph{Attention-based Autoencoder (AbAE\_att)} and \emph{Transformer
Predictor (TP\_att)}, except that now anomaly is estimated by the
attention weights.

The key idea is that when a part of the sequence receives a low
attention weight, it suggests that the information at that moment is
likely noisy and, therefore, unimportant for the task.


\subsection{Conventional Noise Detection}

Alongside machine learning methods, conventional techniques provide a
reliable alternative for detecting noise in time-series data and are
commonly utilized.
%
\emph{Multinomial Noise Exponential filtering (MNE)} is a method used
to remove unwanted frequencies from time-series data, typically EEG
signals. It applies a bandpass filter to the data, allowing signals
within a specific frequency range to pass through while reducing
frequencies outside this range.



%%%%%%%%%%%%
\section{Experimental Setup}
\label{sec:exp}
%%%%%%%%%%%%

This study employs a case analysis to validate the efficacy of the
proposed noise estimation methods. The focus is detecting noise within
electroencephalographic (EEG) signals, recorded via headbands utilized
during slumber to monitor various stages of the user's sleep cycle.

In this analysis, EEG signals collected from a headband with two EEG
channels synchronized with medical-grade EEG devices are
considered. The recorded signal frequency for each channel of the
headband is 128Hz. These signals are grouped into consecutive
30-second segments, and each segment is further annotated by three
experts, into one of five sleep stages: Wake, N1, N2, N3, and
REM. These stages correspond to specific brain activity patterns, such
as slow eye movements, sleep spindles, and other characteristic
waveforms. The goal of the current analysis is to detect the presence
of noise, if any, at any of these segments. In total, 56 recordings
were examined. Each recording refers to the EEG signals acquired by
the headband of a user during a night-long sleep. These signals are
grouped into 30-second consecutive segments.

As a ground-truth method to evaluate the results of the proposed noise
estimation methods, the original estimation method used by
BitBrain, the headband manufacturer, is considered. This method consists of
task-specific algorithms to automatically estimate noise and evaluate
the overall quality of EEG signals, identifying the artifacts in
recordings made using their wearable textile headband.
The dataset is publicly available \cite{boas-dataset}.


\subsection{Data Pre-processing}

Data normalization is required for the machine learning methods to
ensure robust model training and reliable outcomes. It is performed
using statistics derived from the entire training dataset instead of
relying on per-batch calculations. The median and
\emph{interquartile range (IQR)} are used instead of the mean and
standard deviation, respectively, to improve robustness against
outliers. The median measures central tendency and is resistant to
extreme values, and IQR is a measure of statistical dispersion that
represents the spread of the middle 50\% of a dataset and reduces the
influence of outliers by focusing on the range within which the
central portion of the data lies.

% For a particular feature of a time-series $x$, its normalized value $x_{\text{norm}}$ is given:

% \begin{equation}
%     x_{\text{norm}} = \frac{x - \mathrm{median}(x)}{\mathrm{IQR}(x)} \label{eq:robust_norm}
% \end{equation}

% where $\mathrm{median}(x)$ and $\mathrm{IQR}(x)$ are the feature's median value and IQR respectively.

PCA and MNE require raw data that preserves the characteristics of the
original signal, so no normalization is applied for these methods.

To train the machine learning models, the available recordings were
randomly split into training (43 recordings), validation (3
recordings), and testing subsets (10 recordings). Among the testing
recordings, six had zero or one noisy segments are not reported here
as it makes little sense to compare methods on having identified a
single datapoint. For the record, only PCA identified the noisy
segment in only one of the segments.

Table~\ref{tab2} gives the absolute and relative noise density for the
remaining four recordings, arranged in descending order.
Specifically, the table gives the count of 30-second segments within
which at least one artifact is annotated as noise in the ground-truth
labeling. Note that recordings are \emph{not} of equal length.

What is noteworthy is that Recording~A has considerably different
noise rates between the two channels. Since the signals from the
two channels are heavily correlated, this presents an opportunity
for the machine learning methods to demonstrate learning a
comparative model that exploits the fact that the noisy parts of
HB2 are not correlated to their corresponding parts in HB1. However
this is a difficult theory to construct, since it requires
`discovering' correlation first.


\begin{table}[bt]
\caption{Absolute number and percentage of segments with artifacts in
  each channel and recording session.}
\centering
\renewcommand{\arraystretch}{1.3} % Adjust row height
\begin{tabular}{lrrrr}
\toprule
RecID &  A         &  B       &  C & D \\
\midrule
HB1   &   0        & 57 (5\%) & 27 (3\%) & 9 (1\%) \\

HB2   & 151 (14\%) & 56 (5\%) & 26 (3\%) & 9 (1\%) \\
\bottomrule
\end{tabular}
\label{tab2}
\end{table}



\subsection{Training Process and Hyper-parameters}

The implementations of the methods in Table~\ref{tab1} that we used in
our experiments are publicly available. Our implementation of the
machine learning methods have been reposited in Zenodo.\footnote{Cf. \url{https://doi.org/10.5281/zenodo.14842198}}
MNE is used as implemented and configured in the `MNE Tools' Python
package for exploring, visualizing, and analyzing human
neurophysiological data.\footnote{Available from \url{https://mne.tools} and Pypi.}
MNE is a bandpass filter with pre-configured cut-offs specifically
targeting EEG data.

To process the data with the \emph{AE} and \emph{TP} methods, we split
each 30-second segment of EEG data (3840 samples per channel) into 16
smaller chunks of 240 samples each. This point is moot for \emph{LSTM},
\emph{C-LSTM}, and \emph{MNE}.

The Autoencoder methods are trained on sequence reconstruction. The
Predictor methods are trained on predicting sleep stage.
%
To balance the autoencoders' focus on both the amplitude and trends of the
time-series data, we define a custom loss function, called
\emph{BlendedLoss}. This function combines the median and mean of the
powered absolute differences between the predicted values ($\hat{x}$)
and the target values ($x$):
%
$$
\text{Loss} =
  (1 - b)\cdot\mathrm{median}(\lvert \hat{x} - x \rvert^p) +
  b\cdot\mathrm{mean}(\lvert \hat{x} - x \rvert^p)
$$
%
where $p$ is the power parameter that controls the sensitivity of the
loss to differences and $b$ the \emph{blend factor} that controls
the trade-off between learning the overall trend (median error) and
closely following local patterns (mean error).
% A systematic
% investigation of various blend values within the range [0.1, 0.8]
% reveals the impact on the model's performance in data reconstruction.

Revisiting our research hypothesis, we expect methods trained on
predicting sleep stage to outperform methods trained on autoencoding
since they have access to task-specific labels. More generally our
methods are ordered as follows in terms of task-specific knowledge
they have access to:
%
\begin{enumerate}
\item \emph{MNE} is specifically, expertly designed to detect noise in
  EEG signals and has proven to be very effective on this task.
\item \emph{AE\_att} and \emph{TP\_att} implement our hypothesis that
  the attention mechanism can exploit supervision unrelated to anomaly
  detection to automatically extract task-specific knowledge of
  anomalies.
\item \emph{LSTM}, \emph{C-LSTM}, \emph{AE\_err} and \emph{TP\_err}
  are general-purpose autoencoders with minimal access to task-specific
  knowledge in the form of a task-specific loss function.
\end{enumerate}
%
This ordering reflects our prior expectation regarding their relative
performance. \emph{None of the above (neither machine learning nor
manual calibration) has ever had any access to noise annotations
in the training data, but only to sleep-stage annotations.}

For the training configuration, we set the batch size to 512 and
trained the models for a maximum of 1000 epochs with patience of 30
epochs, meaning that if the validation loss does not improve for 30
consecutive epochs, training will stop. We set the learning rate to
1e-4 and use the Adam optimizer to adjust the model
weights. Additionally, we use \emph{ReduceLROnPlateau} scheduling to
reduce the learning rate if the validation loss plateaus.


%%%%%%%%%%%%
\section{Results and Discussion}
\label{sec:results}
%%%%%%%%%%%%

We prepared three validation/testing setups. In the first setup
validation and testing scores are calculated on the original 30-sec
segments where each segments is annotated as `noise' if it includes at
least one sample marked as `noise' in the ground-truth annotation.
In the 5min and 10min-window setups segments evaluation was performed
on 5min and 10min windows. If a method reports noise on any part of
the window and the ground truth also annotates as noisy any part of the
window, the window counts as a true positive. Obviously, these are
easier tasks than the original 30-sec segmentation on two
grounds: (a) positives get less sparse so task becomes less of a
needle-in-a-haystack problem, and (b) learners have access to a longer
context for the same number of input token, which know to be an
important factor in sequence processing \cite{Lee_2021}.

\input{tab_results}

Table~\ref{tab:results} presents F-score, Precision, and Recall
metrics for the evaluated methods on all three evaluation setups.
%
Since all methods give a numerical estimation and not a binary
decision, a threshold was established. The threshold was calculated
on the training data, separately for each method,
as the threshold that makes 1\% of the training data come out
as noise. This is the only piece of prior domain knowledge shared by
all learners.
%
F-score is calculated for $\beta=2$, in order place
more weight on recall than precision. This is due to the fact that
the dataset is very unbalanced and noise instances are rare, even in
the 10min-window setup. F-score is adapted accordingly to reflect
that recall is harder to achieve than precision.

% NOTE: decided against it to not have the actual application
% influence the research result
%In this application, our primary objective is to identify as many
%segments as possible that contain artifacts while allowing for some
%tolerance regarding detecting noisy segments. The principal aim should
%be to reduce the number of instances requiring the application of
%reliable yet non-automated anomaly detection methods. Consequently,
%the key performance metric to prioritize is Recall. For this reason,
%the F2 score is considered, which is a weighted harmonic mean of
%precision and recall, and where recall is given more importance than
%precision.

The first observation is that by comparing the three sub-tables we can
immediately see that the three windows behave as expected, with
results improving with longer windows. By comparing horizontally from
right to left we also see that results improve as noise gets
denser.\footnote{Note that HB1-A is out-of-order in this respect, as
  it has no noise.}
We cannot speculate on whether the top-to-bottom improvement
is due to the longer context or due to denser positives. But either
way, we have clear indications about how task difficulty scales across
the table.

What is directly relevant for our hypothesis are the comparisons
between
(a) attention-based anomaly detection (AE\_att and TP\_att) against
the error-based anomaly detection from the same models (AE\_err and
TP\_err), and (b) models trained on the sleep stage task (TP) against
autoencoded models (AE).
TP\_att generally outperforms all four TP/AE\_err/att combinations,
although autoencoding proved better on HB1-C (primarily LSTM and
secondarily AE\_att) with the gap becoming more pronounced on the
denser setups. 
Although the conditions present in HB1-C are worth investigating,
the results show that the ideas presented here are validated and
promising.

What is also noteworthy is that TP\_att outperforms MNE on HB2-A and HB2-B.
Regarding HB2-A it is worth investigating whether the transformer has
`discovered' the lack of correlation between HB1-A and HB2-A on noisy
segments. Regarding HB2-B, a possible explanation is that TP\_att is
more robust to noise density considerably above the hard-wired 1\%: it
suffers the unavoidable precision loss just as all methods, but it
gets a comparatively higher F-score through perfect recall.



\section{Conclusions and Future Work}
\label{sec:conc}

This paper investigates the extraction of anomaly indicators from
\emph{intermediate} layers of a deep neural network trained on a
sequence processing task. By removing the need to train on a sequence
reconstruction/prediction task, we are free to train on whatever
task-specific supervision is available. This alleviates the most
pressing challenge of anomaly detection, namely that anomalies are
vaguely defined and thus difficult to directly supervise, while
simultaneously allowing task-specific knowledge to be extracted from
whatever other (non anomaly-related) supervision might be available.

Our ideas are positively validated on EEG signals sourced from
wearable sleep-monitoring devices. This dataset has the great
advantage of having both task supervision (sleep stage detection) and
noise supervision, both expertly annotated by the device manufacturer.
Our current findings already indicate that the attention layer of a
Transformer trained on the sleep stage task exhibits promising
performance when used as an anomaly detector.

Subsequent steps will pursue two directions: exploring the current
experimental setup at more depth and expanding the breadth of the
results with diverse datasets and tasks. Regarding the first direction,
we mostly plan to investigate how the components of the attention
layer (Q, K, and V) interact in order to understand whether a subset 
of these components is more tightly fitted on
recognizing patterns that should be ignored. Another investigation
would be to understand if the performance on HB2-A really indicates
that the Transformer has `discovered' the lack of correlation between
HB1-A and HB2-A on noisy segments or is incidental. Despite the
inherent difficulty in trying to understand the inner workings of
neural networks even for single-layer attention, as the the field
of \emph{explainable machine learning} evolves the required tools
are starting to materialize.
%
Regarding the second direction, the most immediate goal is to jointly
train on multiple tasks, which we expect to help the network
distinguish between noisy segments and segments that happen to be
irrelevant for a given task.


\begin{credits}
  
\subsubsection{\ackname} This research was co-funded by the European Union
under GA no. 101135782 (MANOLO project). Views and opinions expressed
are however those of the authors only and do not necessarily reflect
those of the European Union or CNECT. Neither the European Union nor
CNECT can be held responsible for them. AWS resources were provided by
the National Infrastructures for Research and Technology GRNET and
funded by the EU Recovery and Resiliency Facility.

\subsubsection{\discintname} The authors have no competing
interests.
\end{credits}

% \section*{References}

\bibliographystyle{splncs04}
\bibliography{refs}

\end{document}


% LocalWords:  autoencode stationarity datapoint Mejri PCA LSTM IQR
% LocalWords:  autoencoder dimensionality LeakyReLU BlendedLoss MNE
% LocalWords:  neurophysiological overfit MANOLO CNECT Zenodo
% LocalWords:  cyberattack autoencoding recurrency softmax bandpass
% LocalWords:  convolutional interquartile ReduceLROnPlateau
