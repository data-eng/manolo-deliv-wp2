%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------
\documentclass[aspectratio=169,xcolor=dvipsnames, t]{beamer}
\usepackage{fontspec}
\usetheme{SimplePlusAIC}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{svg}
\usepackage{tikz}
\usepackage{makecell}
\usepackage{wrapfig}


% Used to v-align the logos in the \date line
\newcommand{\vcenteredlogo}[1]{\begingroup
\setbox0=\hbox{\includegraphics[height=20pt]{#1}}%
\parbox{\wd0}{\box0}\endgroup}

\newcommand{\textbfblue}[1]{\textbf{\textcolor{PrussianBlue}{#1}}}


%----------------------------------------------------------------------------------------
%	TITLE PAGE CONFIGURATION
%----------------------------------------------------------------------------------------

\title[short title]{Self-Attention as a Predictor of EEG Anomalies}
\subtitle{}

\author{\vskip -15pt Natalia Koliou (presenter),
  \\ Maria Sierra, Christoforos Romesis,
  \\ Stasinos Konstantopoulos, and Luis Montesano}
\institute[\textit{Self-Attention as a Predictor of EEG Anomalies}]{}

\date{%
%   \vcenteredlogo{AICStyleData/logos/bitbrain.png}%
%   \hspace{2em}%
  \vcenteredlogo{AICStyleData/logos/manolo-tagline.png}%
  \hspace{2em}%
  \vcenteredlogo{AICStyleData/logos/euflag-white.png}%
  \hfill 25 Oct 2025 \hspace*{0.15\linewidth}%
}

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

\begin{document}

\maketitlepage

%------------------------------------------------
% Overview
\begin{frame}[t]{Overview}
    \tableofcontents
\end{frame}

%------------------------------------------------
% Introduction & Background
\makesection{Introduction \& Background}

\begin{frame}{Introduction \& Background}
\begin{itemize}
    \item EEG signals are highly sensitive, low-amplitude recordings easily contaminated by \textbfblue{artifacts} (noise not generated by brain activity).
    \item Artifacts may arise from physiological (muscle tension, sweating) or technical sources (electrode detachment).
    \item What counts as “noise” is often \textbfblue{task-dependent}: a feature irrelevant for one application may be meaningful for another.
    \item Traditional denoising via \textbfblue{reconstruction/prediction errors} (Autoencoders, LSTMs) ignores contextual relevance.
    \item \textbfblue{Our idea:} Train attention-based models on a downstream task (e.g., sleep stage classification) and use its attention patterns to infer anomalies without explicit artifact labels.
\end{itemize}
\end{frame}

%------------------------------------------------
% Research Methodology
\makesection{Research Methodology}

\begin{frame}{Research Methodology}
    \begin{itemize}
        \item Traditional anomaly detection uses \textbfblue{reconstruction or prediction errors}, but these often miss \textbfblue{context-specific anomalies}.
        \item \textbfblue{Reconstruction error} can fail because models may learn to reproduce artifacts if trained on contaminated data (false negatives).
        \item \textbfblue{Prediction error} can incorrectly flag unpredictable but normal variations as anomalies (false positives).
        \item The \textbfblue{attention-based approach} assumes that \textbfblue{low-attention regions} correspond to noisy or irrelevant segments.
    \end{itemize}

    \vspace{1em}

    \textbfblue{Hypothesis:} during a task (e.g., reconstruction or prediction), the model learns to ignore artifacts that hinder performance.
\end{frame}

\begin{frame}{Research Methodology}

    \begin{table}[bt]
    \centering
        \begin{tabular}{lp{6cm}p{2cm}}
        \toprule
        \textbfblue{\emph{Acronym}}   & \textbfblue{\emph{Architecture}}& \textbfblue{\emph{Detection}}  \\
        \midrule
        \textit{LSTM}    & LSTM Autoencoder   & Reconstruction  \\
        \textit{C-LSTM}  & Convolutional LSTM Autoencoder
                                            & error  \\
        \textit{AE\_err} & Attention-based Autoencoder
                                            &   \\
        \midrule
        \textit{TP\_err} & Transformer Predictor
                                            & Prediction error  \\
        \midrule
        \textit{AE\_att} & Attention-based Autoencoder
                                            & Attention \\
        \textit{TP\_att} & Transformer Predictor &  \\
        \midrule
        \textit{MNE}     & \multicolumn{2}{l}{IIR filter} \\
        \bottomrule
        \end{tabular}
    \end{table}

\end{frame}

\begin{frame}{Research Methodology}
    \begin{figure}
        \centering
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figures/Fig2.png}
        \end{minipage}
        \hspace{3em}
        \begin{minipage}{0.30\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figures/Fig3.png}
        \end{minipage}
        \vspace{1.5em}
        {\small \textit{Left: AE\_err/AE\_att architecture \hspace{8em} TP\_err/TP\_att architecture}}
    \end{figure}
\end{frame}

%------------------------------------------------
% Experiments
\makesection{Experiments}

%------------------------------------------------
% Data Preprocessing
\begin{frame}{Data Preprocessing}

    Our approach was evaluated using the \textbfblue{BOAS dataset}: 
    \vspace{0.5em}

    \begin{itemize}
        \item EEG signals recorded from a \textbfblue{two-channel headband} at \textbfblue{128 Hz}.
        \item Signals segmented into \textbfblue{30s epochs}, each labeled into five sleep stages (Wake, N1, N2, N3, REM).
        \item \textbfblue{56 overnight recordings} from different users in total; 43 train, 3 validation, 10 test.
        \item Data normalized using \textbfblue{median and IQR} for robustness (skipped for MNE to preserve signal shape).
        \item Ground truth from Bitbrain's \textbfblue{proprietary artifact estimation algorithm}.
    \end{itemize}

    \vspace{0.5em}
    {\small \textit{\underline{Note}: 6 test recordings have minimal noise; comparisons focus on the remaining 4.}}

\end{frame}

%------------------------------------------------
% Training Process \& Hyperparameters
\begin{frame}{Training Process \& Hyperparameters}
    \begin{itemize}
        \item EEG segments (30s, 3840 samples/channel) split into \textbfblue{16 chunks of 240 samples} for AE and TP methods.
        \item Custom \textbfblue{BlendedLoss} balances trend (median) and local pattern (mean) errors: 
        \[
        \text{Loss} = (1-b) \cdot \text{median}(|\hat{x}-x|^p) + b \cdot \text{mean}(|\hat{x}-x|^p)
        \]
        \item Methods compared:
        \begin{enumerate}
            \item \textbfblue{MNE}: expert-designed EEG noise filter.
            \item \textbfblue{AE\_att / TP\_att}: anomalies inferred via attention weights.
            \item \textbfblue{LSTM, C-LSTM, AE\_err, TP\_err}: anomalies inferred via reconstruction/prediction errors.
        \end{enumerate}
        \item \textbfblue{Training setup:} batch size: 512, epochs: 1000, patience: 30, optimizer: Adam, \\lr: 1e-4, scheduler: ReduceLROnPlateau.
    \end{itemize}
\end{frame}

%------------------------------------------------
% Results \& Discussion
\makesection{Results \& Discussion}

%------------------------------------------------
% Results \& Discussion
\begin{frame}{Results \& Discussion}
    \begin{itemize}
        \item Three evaluation setups: \textbfblue{30s, 5min, 10min windows}.
        \item Window marked as \textbfblue{noisy} if any sample is annotated as noise.
        \item Predictions binarized with \textbfblue{threshold}: 1\% of training data marked as noise.
        \item \textbfblue{F2-score (\(\beta=2\))} emphasizes recall to account for the strong class imbalance.
        \item \textbfblue{Longer windows} improve results due to denser positives and more context.
        \item Attention-based methods (AE\_att, TP\_att) outperform error-based counterparts (AE\_err, TP\_err).
        \item TP\_att outperforms MNE on some recordings, likely due to better handling of \textbfblue{uncorrelated channel segments}.
    \end{itemize}

    \vspace{0.5em}
    {\small \textit{Attention is a promising indicator for anomaly detection in EEG signals.}}

\end{frame}

%------------------------------------------------
% Conclusion & Future Work
\makesection{Conclusion \& Future Work}

\begin{frame}{Conclusion}
    \begin{itemize}
        \item We extract \textbfblue{anomaly indicators} from intermediate layers of deep networks trained on sequence tasks, without needing explicit anomaly labels.
        \item Validated on \textbfblue{EEG signals} from wearable sleep monitoring devices.
        \item Attention layers show promising performance for anomaly detection.
    \end{itemize}
\end{frame}

\begin{frame}{Future Work}
    \begin{itemize}
        \item Analyze \textbfblue{attention components} (Q, K, V) to understand which parts focus on ignoring noisy patterns.
        \item Investigate model robustness to \textbfblue{uncorrelated/noisy} segments.
        \item Extend experiments to \textbfblue{diverse} datasets and tasks.
        \item Explore \textbfblue{multi-task training} to better distinguish between noise and task-irrelevant segments.
        \item Use \textbfblue{explainable ML} tools to interpret attention-based anomaly detection more transparently.
    \end{itemize}
\end{frame}

%------------------------------------------------
% Citations
% \begin{frame}{References}
%     % Beamer does not support BibTeX so references must be inserted manually as below
%     \footnotesize{
%         \begin{thebibliography}{99}
%             \bibitem[Smith, 2012]{p1} John Smith (2012)
%             \newblock Title of the publication
%             \newblock \emph{Journal Name} 12(3), 45 -- 678.

%             \bibitem[Doe, 2012]{p1} Joe Doe (2012)
%             \newblock Title of the publication
%             \newblock \emph{Journal Name} 12(3), 45 -- 678.
%             \bibitem[Doe, 2013]{p} Jane Doe (2012)
%             \newblock Title of the publication
%             \newblock \emph{Journal Name} 12(3), 45 -- 678.
%         \end{thebibliography}
%     }
% \end{frame}

%------------------------------------------------
% Thank you

\begin{frame}{Thank you for your attention!}

\begin{block}{Thank you for your attention! Any questions?}

\begin{tabular}{p{0.8\linewidth}p{0.2\linewidth}}

Natalia Kolliou, Christoforos Romesis, Stasinos Konstantopoulos &
\vcenteredlogo{AICStyleData/logos/deg.png}
\vcenteredlogo{AICStyleData/logos/ncsr.png} \\
Maria Sierra, Luis Montesano &
\vcenteredlogo{AICStyleData/logos/bitbrain.png} \\

\end{tabular}

\end{block}

\begin{tabular}{p{0.65\linewidth}p{0.3\linewidth}}
\footnotesize\it
This research was co-funded by the European Union under
GA no. 101135782 (MANOLO project). Views and opinions expressed are
however those of the authors only and do not necessarily reflect those
of the European Union or CNECT. Neither the European Union nor CNECT
can be held responsible for them.
&
\vskip -6pt
\includegraphics[height=20pt]{AICStyleData/logos/euflag.png}
\includegraphics[height=30pt]{AICStyleData/logos/manolo-tagline-dark.png}
\\
\tt https://manolo-project.eu
\end{tabular}


\end{frame}
%----------------------------------------------------------------------------------------
% \makefinalpage
%----------------------------------------------------------------------------------------
\end{document}
