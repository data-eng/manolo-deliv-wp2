%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------
\documentclass[aspectratio=169,xcolor=dvipsnames, t]{beamer}
\usepackage{fontspec}
\usetheme{SimplePlusAIC}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{svg}
\usepackage{tikz}
\usepackage{makecell}
\usepackage{wrapfig}


% Used to v-align the logos in the \date line
\newcommand{\vcenteredlogo}[1]{\begingroup
\setbox0=\hbox{\includegraphics[height=20pt]{#1}}%
\parbox{\wd0}{\box0}\endgroup}

\newcommand{\textbfblue}[1]{\textbf{\textcolor{PrussianBlue}{#1}}}


%----------------------------------------------------------------------------------------
%	TITLE PAGE CONFIGURATION
%----------------------------------------------------------------------------------------

\title[short title]{Self-Attention as a Predictor of EEG Anomalies}
\subtitle{}

\author{\vskip -15pt Natalia Koliou (presenter),
  \\ Maria Sierra, Christoforos Romesis,
  \\ Stasinos Konstantopoulos, and Luis Montesano}
\institute[\textit{Self-Attention as a Predictor of EEG Anomalies}]{}

\date{%
%   \vcenteredlogo{AICStyleData/logos/bitbrain.png}%
%   \hspace{2em}%
  \vcenteredlogo{AICStyleData/logos/manolo-tagline.png}%
  \hspace{2em}%
  \vcenteredlogo{AICStyleData/logos/euflag-white.png}%
  \hfill 25 Oct 2025 \hspace*{0.15\linewidth}%
}

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

\begin{document}

\maketitlepage

%------------------------------------------------
% Overview
\begin{frame}[t]{Overview}
    \tableofcontents
\end{frame}

%------------------------------------------------
% Introduction & Background
\makesection{Introduction \& Background}

\begin{frame}{Introduction \& Background}
\begin{itemize}
    \item EEG signals are highly sensitive, low-amplitude recordings easily contaminated by \textbfblue{artifacts} (noise not generated by brain activity).
    \item Artifacts may arise from physiological (muscle tension, sweating) or technical sources (electrode detachment).
    \item What counts as “noise” is often \textbfblue{task-dependent}: a feature irrelevant for one application may be meaningful for another.
    \item Traditional denoising via \textbfblue{reconstruction/prediction errors} (Autoencoders, LSTMs) ignores contextual relevance.
    \item \textbfblue{Our idea:} Train an attention-based model on a downstream task (e.g., sleep stage classification) and use its attention patterns to infer anomalies without explicit artifact labels.
\end{itemize}
\end{frame}

%------------------------------------------------
% Research Methodology
\makesection{Research Methodology}

\begin{frame}{Research Methodology}
    \begin{itemize}
        \item Counterfactual explanations provide \textbfblue{instance-based insights} for time-series classifiers.
        \item The goal is to explain why a classifier predicts a certain label:
        \begin{itemize}
            \item Dataset: $D = \{x^{(i)}\}_{i=1}^N$, each $x^{(i)} \in \mathbb{R}^d$.
            \item Classifier: $C: \mathcal{X} \rightarrow \mathcal{Y}$, labels $\mathcal{Y} = \{1, \dots, n\}$.
            \item For input $x$, predicted label $y = C(x)$.
        \end{itemize}
        \item For misclassified instances $x_m$ with $C(x_m) \neq y^*(x_m)$, find \textbfblue{minimal modification} $x'_m$ such that $C(x'_m) = y^*(x_m)$ and $x'_m$ is close to $x_m$.
        \item $\Delta x_m = x'_m - x_m$ reveals dominant patterns influencing the classifier's decision.
    \end{itemize}
\end{frame}

% \begin{frame}{Research Methodology}
%     \vspace{-1.5em}
%     \begin{figure}
%         \centering
%         \includegraphics[height=0.68\paperheight]{figures/xstae_arch.png}
%     \end{figure}
% \end{frame}


%------------------------------------------------
% Experiments
\makesection{Experiments}

%------------------------------------------------
% Data Preprocessing
\begin{frame}{Data Preprocessing}

    We use the \textbfblue{BOAS EEG dataset}, with 128 full-night recordings from 2 channels (256 Hz), to explain classifier errors across 4 sleep stages (N1, N2, N3, REM).
    \vspace{1.5em}

    \begin{itemize}
        \item \textbfblue{EEG Data:} 
        \begin{itemize}
            \item 30s epochs ($n_s = 7680$ samples, $n_c = 2$).
            \item FFT $\rightarrow$ 0.4-30 Hz filtering $\rightarrow$ segment into $n_s'=300$ spectral slices.
            \item Extract 3 features per slice (frequency, phase, amplitude).
        \end{itemize}
        \item \textbfblue{Classifier:} Two-stage convolutional network over sequences of $k=5$ epochs:
        \[
            X_t^f = [e_{t-k+1}, \dots, e_t] \rightarrow \hat{y}_t
        \]
        \item \textbfblue{Autoencoders:} Hybrid networks with convolutional and attention layers:
        \[
        X_f^t = e_t \oplus \text{pos} \longrightarrow \hat{X}_f^{\,t} \text{ (reconstructed input)}
        \]
    \end{itemize}

\end{frame}

%------------------------------------------------
% Training Process \& Hyperparameters
\begin{frame}{Training Process \& Hyperparameters}
    \begin{itemize}
        \item We pass the test dataset through each class-specific autoencoder, then classify the restyled outputs using the original classifier.
        \item High \textbfblue{classification accuracy} on restyled signals indicates the autoencoders have learned the patterns that the classifier uses for each sleep stage.
    \end{itemize}

    \vspace{2em}
    \centering
    \begin{tabular}{lcccc}
        \toprule
        Metric & N1 & N2 & N3 & REM \\
        \midrule
        Accuracy & 0.9997 & 0.9998 & 0.9260 & 0.9986 \\
        \bottomrule
    \end{tabular}
\end{frame}

%------------------------------------------------
% Results \& Discussion
\makesection{Results \& Discussion}

%------------------------------------------------
% Results \& Discussion
\begin{frame}{Results \& Discussion}

    We use the \textbfblue{BOAS EEG dataset}, with 128 full-night recordings from 2 channels (256 Hz), to explain classifier errors across 4 sleep stages (N1, N2, N3, REM).
    \vspace{1.5em}

    \begin{itemize}
        \item \textbfblue{EEG Data:} 
        \begin{itemize}
            \item 30s epochs ($n_s = 7680$ samples, $n_c = 2$).
            \item FFT $\rightarrow$ 0.4-30 Hz filtering $\rightarrow$ segment into $n_s'=300$ spectral slices.
            \item Extract 3 features per slice (frequency, phase, amplitude).
        \end{itemize}
        \item \textbfblue{Classifier:} Two-stage convolutional network over sequences of $k=5$ epochs:
        \[
            X_t^f = [e_{t-k+1}, \dots, e_t] \rightarrow \hat{y}_t
        \]
        \item \textbfblue{Autoencoders:} Hybrid networks with convolutional and attention layers:
        \[
        X_f^t = e_t \oplus \text{pos} \longrightarrow \hat{X}_f^{\,t} \text{ (reconstructed input)}
        \]
    \end{itemize}

\end{frame}

%------------------------------------------------
% Conclusion & Future Work
\makesection{Conclusion \& Future Work}

\begin{frame}{Conclusion}
\begin{itemize}
    \item \textbfblue{xSTAE} explains classifier errors by restyling misclassified EEG instances into correctly classified ones.
    \item Autoencoders balance \textbfblue{identity loss} (keep instance similar) and \textbfblue{classification loss} (push to correct label), revealing features the classifier missed.
    \item Contributions:
    \begin{itemize}
        \item Ground counterfactual explanations in time-series EEG classification.
        \item Identify spectral representations suitable for EEG signals.
        \item Validate on open BOAS dataset and release full experimental setup.
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Future Work}
\begin{itemize}
    \item Explore \textbfblue{alternative identity losses} to highlight meaningful changes (e.g., bigger local changes, selective brainwave bands).
    \item Conduct \textbfblue{expert trials} to refine interpretability of restyled EEGs.
    \item Investigate linking insights from misclassifications to \textbfblue{actionable guidance} at the data or confidence level, keeping xSTAE model-agnostic.
\end{itemize}
\end{frame}

%------------------------------------------------
% Citations
% \begin{frame}{References}
%     % Beamer does not support BibTeX so references must be inserted manually as below
%     \footnotesize{
%         \begin{thebibliography}{99}
%             \bibitem[Smith, 2012]{p1} John Smith (2012)
%             \newblock Title of the publication
%             \newblock \emph{Journal Name} 12(3), 45 -- 678.

%             \bibitem[Doe, 2012]{p1} Joe Doe (2012)
%             \newblock Title of the publication
%             \newblock \emph{Journal Name} 12(3), 45 -- 678.
%             \bibitem[Doe, 2013]{p} Jane Doe (2012)
%             \newblock Title of the publication
%             \newblock \emph{Journal Name} 12(3), 45 -- 678.
%         \end{thebibliography}
%     }
% \end{frame}

%------------------------------------------------
% Thank you

\begin{frame}{Thank you for your attention!}

\begin{block}{Thank you for your attention! Any questions?}

\begin{tabular}{p{0.8\linewidth}p{0.2\linewidth}}

Natalia Kolliou, Christoforos Romesis, Stasinos Konstantopoulos &
\vcenteredlogo{AICStyleData/logos/deg.png}
\vcenteredlogo{AICStyleData/logos/ncsr.png} \\
Maria Sierra, Luis Montesano &
\vcenteredlogo{AICStyleData/logos/bitbrain.png} \\

\end{tabular}

\end{block}

\begin{tabular}{p{0.65\linewidth}p{0.3\linewidth}}
\footnotesize\it
This research was co-funded by the European Union under
GA no. 101135782 (MANOLO project). Views and opinions expressed are
however those of the authors only and do not necessarily reflect those
of the European Union or CNECT. Neither the European Union nor CNECT
can be held responsible for them.
&
\vskip -6pt
\includegraphics[height=20pt]{AICStyleData/logos/euflag.png}
\includegraphics[height=30pt]{AICStyleData/logos/manolo-tagline-dark.png}
\\
\tt https://manolo-project.eu
\end{tabular}


\end{frame}
%----------------------------------------------------------------------------------------
% \makefinalpage
%----------------------------------------------------------------------------------------
\end{document}
