@book{basseville1993detection,
  author = {Michèle Basseville and Igor V. Nikiforov},
  title = {Detection of Abrupt Changes: Theory and Application},
  year = {1993},
  publisher = {Prentice-Hall},
  address = {Englewood Cliffs, NJ},
  isbn = {0-13-126780-9}
}

@misc{ncss2024,
  author = {NCSS Statistical Software},
  title = {CUSUM Charts},
  howpublished = {Online source, \url{https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/NCSS/CUSUM_Charts.pdf}},
  note = {Last accessed: November 2024},
  url = {https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/NCSS/CUSUM_Charts.pdf}
}

@article{nelson1984shewhart,
  author = {Lloyd S. Nelson},
  title = {The Shewhart Control Chart—Tests for Special Causes},
  journal = {Journal of Quality Technology},
  volume = {16},
  number = {4},
  pages = {237-239},
  year = {1984},
  doi = {10.1080/00224065.1984.11978921}
}

@article{koshti2011cusum,
  author = {Vijay Koshti},
  title = {Cumulative sum control chart},
  journal = {International Journal of Physics and Mathematical Sciences},
  year = {2011},
  issn = {2277-2111}
}

@InCollection{Lee_2021,
   author={Lee, Ming-Chang and Lin, Jia-Chun and Gran, Ernst Gunnar},   
   title={How Far Should We Look Back to Achieve Effective Real-Time Time-Series Anomaly Detection?},
   ISBN={9783030751005},
   ISSN={2367-3389},
   urlx={http://dx.doi.org/10.1007/978-3-030-75100-5_13},
   year={2021},
   doi={10.1007/978-3-030-75100-5_13},
   booktitle={Advanced Information Networking and Applications},
   publisher={Springer}
}

@inproceedings{artyushenko2021modeling,
  author = {V. M. Artyushenko and V. I. Volovach},
  title = {Modeling the Algorithm of Cumulative Sums in the Applied Problems of Detecting the Signals with Random Time of Occurrence in non-Gaussian Noise},
  booktitle = {2021 Systems of Signals Generating and Processing in the Field of on Board Communications},
  year = {2021},
  pages = {1-5},
  address = {Moscow, Russia},
  doi = {10.1109/IEEECONF51389.2021.9416051}
}

@inproceedings{volovach2021detection,
  author = {V. I. Volovach and V. M. Artyushenko},
  title = {Detection of Signals with a Random Moment of Occurrence Using the Cumulative Sum Algorithm},
  booktitle = {2021 Systems of Signals Generating and Processing in the Field of on Board Communications},
  year = {2021},
  pages = {1-6},
  address = {Moscow, Russia},
  doi = {10.1109/IEEECONF51389.2021.9415982}
}

@article{tam2009theoretical,
  author = {D. Tam},
  title = {A Theoretical Analysis of Cumulative Sum Slope (CUSUM-Slope) Statistic for Detecting Signal Onset (begin) and Offset (end) Trends from Background Noise Level},
  journal = {The Open Mathematics, Statistics and Probability Journal},
  year = {2009},
  month = {June}
}

@article{yi2021adaptive,
  author = {Fan Yi and Peihua Qiu},
  title = {An adaptive CUSUM chart for drift detection},
  journal = {Quality and Reliability Engineering International},
  volume = {38},
  year = {2021},
  doi = {10.1002/qre.3020}
}

@inproceedings{sebastiao2017supporting,
  author = {R. Sebastião and J. M. Fernandes},
  title = {Supporting the Page-Hinkley test with empirical mode decomposition for change detection},
  booktitle = {International Symposium on Methodologies for Intelligent Systems},
  pages = {492-498},
  year = {2017},
  publisher = {Springer, Cham},
}

@article{mouss2004test,
  author = {Hayet Mouss and M.Djamel Mouss and Kinza Mouss and Linda Sefouhi},
  title = {Test of Page-Hinckley, an approach for fault detection in an agro-alimentary production system},
  journal = {Proceedings of the 5th International Symposium on Automation and Control},
  volume = {2},
  pages = {815-818},
  year = {2004},
  doi = {10.1109/ASCC.2004.184970},
}

@misc{ali2023understanding,
  author = {Moez Ali},
  title = {Understanding Data Drift and Model Drift: Drift detection in Python},
  howpublished = {Online source, \url{https://www.datacamp.com/tutorial/understanding-data-drift-model-drift}},
  month = {January},
  year = {2023},
  url = {https://www.datacamp.com/tutorial/understanding-data-drift-model-drift},
  note = {Last accessed: November 2024},
}

@incollection{joyce2011kullback,
  author = {James Joyce},
  title = {{K}ullback-{L}eibler Divergence},
  booktitle = {Encyclopedia of Complexity and Systems Science},
  pages = {3373-3381},
  year = {2011},
  publisher = {Springer},
  doi = {10.1007/978-3-642-04898-2_327},
}

@misc{shlens2014notes,
  author = {Jonathon Shlens},
  title = {Notes on {K}ullback-{L}eibler Divergence and Likelihood Theory},
  year = {2014},
  note = {Online source},
}

@article{vanerven2014renyi,
  author = {T. van Erven and P. Harremos},
  title = {{R}ényi Divergence and {K}ullback-{L}eibler Divergence},
  journal = {IEEE Transactions on Information Theory},
  volume = {60},
  number = {7},
  pages = {3797-3820},
  year = {2014},
  doi = {10.1109/TIT.2014.2320500},
}

@inproceedings{hershey2007approximating,
  author = {J. R. Hershey and P. A. Olsen},
  title = {Approximating the {K}ullback {L}eibler Divergence Between Gaussian Mixture Models},
  booktitle = {2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07},
  pages = {IV-317-IV-320},
  year = {2007},
  doi = {10.1109/ICASSP.2007.366913},
}

@article{bro2014principal,
  author = {R. Bro and A. K. Smilde},
  title = {Principal component analysis},
  journal = {Analytical Methods},
  volume = {6},
  number = {9},
  pages = {2812-2831},
  year = {2014},
  doi = {10.1039/c3ay41907j},
}

@article{abdi2010principal,
  author = {Hervé Abdi and Lynne Williams},
  title = {Principal Component Analysis},
  journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
  volume = {2},
  pages = {433-459},
  year = {2010},
  doi = {10.1002/wics.101},
}

@article{jolliffe2016principal,
  author = {Ian T. Jolliffe and Jorge Cadima},
  title = {Principal component analysis: a review and recent developments},
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {374},
  number = {2065},
  year = {2016},
  doi = {10.1098/rsta.2015.0202},
}

@inproceedings{shao2014prototype,
  author = {Junming Shao and Zahra Ahmadi and Stefan Kramer},
  title = {Prototype-based learning on concept-drifting data streams},
  booktitle = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year = {2014},
  doi = {10.1145/2623330.2623609},
}

@inproceedings{bifet2007learning,
  author = {Albert Bifet and Ricard Gavaldà},
  title = {Learning from Time-Changing Data with Adaptive Windowing},
  booktitle = {Proceedings of the 7th SIAM International Conference on Data Mining},
  year = {2007},
  pages = {42},
  doi = {10.1137/1.9781611972771.42},
}

@article{sun2016online,
  author = {Y. Sun and Z. Wang and H. Liu and C. Du and J. Yuan},
  title = {Online Ensemble Using Adaptive Windowing for Data Streams with Concept Drift},
  journal = {International Journal of Distributed Sensor Networks},
  volume = {12},
  number = {5},
  year = {2016},
  doi = {10.1155/2016/4218973},
}

@INPROCEEDINGS{imagenet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi={10.1109/CVPR.2009.5206848}}


@inproceedings{laion,
 author = {Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and Schramowski, Patrick and Kundurthy, Srivatsa and Crowson, Katherine and Schmidt, Ludwig and Kaczmarczyk, Robert and Jitsev, Jenia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {25278--25294},
 publisher = {Curran Associates, Inc.},
 title = {LAION-5B: An open large-scale dataset for training next generation image-text models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/a1859debfb3b59d094f3504d5ebb6c25-Paper-Datasets_and_Benchmarks.pdf},
 volume = {35},
 year = {2022}
}


@InProceedings{Schramowski_2023_CVPR,
    author    = {Schramowski, Patrick and Brack, Manuel and Deiseroth, Bj\"orn and Kersting, Kristian},
    title     = {Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {22522-22531}
}







@article{imagen,
author = {Daniel Koehler},
title ={More than anything: Advocating for synthetic architectures within large-scale language-image models},

journal = {International Journal of Architectural Computing},
volume = {21},
number = {2},
pages = {242-255},
year = {2023},
doi = {10.1177/14780771231170455},

URL = { 
    
        https://doi.org/10.1177/14780771231170455
    
    

},
eprint = { 
    
        https://doi.org/10.1177/14780771231170455
    
    

}
,
    abstract = { Large-scale language-image (LLI) models have the potential to open new forms of critical practice through architectural research. Their success enables designers to research within discourses that are profoundly connected to the built environment but did not previously have the resources to engage in spatial research. Although LLI models do not generate coherent building ensembles, they offer an esthetic experience of an AI infused design practice. This paper contextualizes diffusion models architecturally. Through a comparison of approaches to diffusion models in architecture, this paper outlines data-centric methods that allow architects to design critically using computation. The design of text-driven latent spaces extends the histories of typological design to synthetic environments including non-building data into an architectural space. More than synthesizing quantic ratios in various arrangements, the architect contributes by assessing new categorical differences into generated work. The architects’ creativity can elevate LLI models with a synthetic architecture, nonexistent in the data sets the models learned from. }
}


@article{guimaraes2024pre,
  title={Pre-trained language models: What do they know?},
  author={Guimar{\~a}es, Nuno and Campos, Ricardo and Jorge, Al{\'\i}pio},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={14},
  number={1},
  pages={e1518},
  year={2024},
  publisher={Wiley Online Library}
}


@article{energyhouseholds,
author = {Wang, Qiang and Li, Yuanfan and Li, Rongrong},
year = {2024},
month = {08},
pages = {},
title = {Ecological footprints, carbon emissions, and energy transitions: the impact of artificial intelligence (AI)},
volume = {11},
journal = {Humanities and Social Sciences Communications},
doi = {10.1057/s41599-024-03520-5}
}

@ARTICLE{dd_survey,
  author={Lei, Shiye and Tao, Dacheng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A Comprehensive Survey of Dataset Distillation}, 
  year={2024},
  volume={46},
  number={1},
  pages={17-32},
  keywords={Training;Metalearning;Synthetic data;Deep learning;Surveys;Data models;Codes;Efficient deep learning;neural network;data compression;dataset distillation},
  doi={10.1109/TPAMI.2023.3322540}}


@INPROCEEDINGS {datadam,
author = { Sajedi, Ahmad and Khaki, Samir and Amjadian, Ehsan and Liu, Lucy Z. and Lawryshyn, Yuri A. and Plataniotis, Konstantinos N. },
booktitle = { 2023 IEEE/CVF International Conference on Computer Vision (ICCV) },
title = {{ DataDAM: Efficient Dataset Distillation with Attention Matching }},
year = {2023},
volume = {},
ISSN = {},
pages = {17051-17061},
abstract = { Researchers have long tried to minimize training costs in deep learning while maintaining strong generalization across diverse datasets. Emerging research on dataset distillation aims to reduce training costs by creating a small synthetic set that contains the information of a larger real dataset and ultimately achieves test accuracy equivalent to a model trained on the whole dataset. Unfortunately, the synthetic data generated by previous methods are not guaranteed to distribute and discriminate as well as the original training data, and they incur significant computational costs. Despite promising results, there still exists a significant performance gap between models trained on condensed synthetic sets and those trained on the whole dataset. In this paper, we address these challenges using efficient Dataset Distillation with Attention Matching (DataDAM), achieving state-of-the-art performance while reducing training costs. Specifically, we learn synthetic images by matching the spatial attention maps of real and synthetic data generated by different layers within a family of randomly initialized neural networks. Our method outperforms the prior methods on several datasets, including CIFAR10/100, TinyImageNet, ImageNet-1K, and subsets of ImageNet-1K across most of the settings, and achieves improvements of up to 6.5% and 4.1% on CIFAR100 and ImageNet-1K, respectively. We also show that our high-quality distilled images have practical benefits for downstream applications, such as continual learning and neural architecture search. },
keywords = {Training;Deep learning;Computer vision;Costs;Computational modeling;Neural networks;Training data},
doi = {10.1109/ICCV51070.2023.01568},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV51070.2023.01568},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Oct}


@article{bengio2013estimating,
  title={Estimating or propagating gradients through stochastic neurons for conditional computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}

@article{hartigan1979algorithm,
  title={Algorithm AS 136: A k-means clustering algorithm},
  author={Hartigan, John A and Wong, Manchek A},
  journal={Journal of the royal statistical society. series c (applied statistics)},
  volume={28},
  number={1},
  pages={100--108},
  year={1979},
  publisher={JSTOR}
}

@INPROCEEDINGS{8285168,
  author={Wan, Zhiqiang and Zhang, Yazhou and He, Haibo},
  booktitle={2017 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={Variational autoencoder based synthetic data generation for imbalanced learning}, 
  year={2017},
  volume={},
  number={},
  pages={1-7},
  keywords={Sampling methods;Training;Decoding;Computer architecture;Euclidean distance;Data models},
  doi={10.1109/SSCI.2017.8285168}}
